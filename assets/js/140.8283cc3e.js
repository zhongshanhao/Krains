(window.webpackJsonp=window.webpackJsonp||[]).push([[140],{622:function(a,e,v){"use strict";v.r(e);var _=v(4),t=Object(_.a)({},(function(){var a=this,e=a.$createElement,v=a._self._c||e;return v("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[v("h1",{attrs:{id:"hadoop"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hadoop"}},[a._v("#")]),a._v(" hadoop")]),a._v(" "),v("ul",[v("li",[a._v("分布式系统架构")]),a._v(" "),v("li",[a._v("主要解决海量数据的 存储 和 分析计算 问题")]),a._v(" "),v("li",[a._v("泛指Hadoop生态圈")])]),a._v(" "),v("p",[a._v("三篇google论文")]),a._v(" "),v("p",[a._v("GFS--\x3eHDFS")]),a._v(" "),v("p",[a._v("Map-Reduce--\x3eMR")]),a._v(" "),v("p",[a._v("BigTable--\x3eHBase")]),a._v(" "),v("p",[a._v("常用端口号")]),a._v(" "),v("table",[v("thead",[v("tr",[v("th",[a._v("端口")]),a._v(" "),v("th",[a._v("Hadoop2.x")]),a._v(" "),v("th",[a._v("Hadoop3.x")])])]),a._v(" "),v("tbody",[v("tr",[v("td",[a._v("NameNode内部通信端口")]),a._v(" "),v("td",[a._v("8020/9000")]),a._v(" "),v("td",[a._v("8020/9000/9820")])]),a._v(" "),v("tr",[v("td",[a._v("NameNode HTTP UI")]),a._v(" "),v("td",[a._v("50070")]),a._v(" "),v("td",[a._v("9870")])]),a._v(" "),v("tr",[v("td",[a._v("MapReduce查看执行任务端口")]),a._v(" "),v("td",[a._v("8088")]),a._v(" "),v("td",[a._v("8088")])]),a._v(" "),v("tr",[v("td",[a._v("历史服务器通信端口")]),a._v(" "),v("td",[a._v("19888")]),a._v(" "),v("td",[a._v("19888")])])])]),a._v(" "),v("p",[a._v("常用配置文件")]),a._v(" "),v("p",[a._v("3.x core-site.xml\thdfs-site.xml\tyarn-site.xml\tmapred.site.xml\tworkers")]),a._v(" "),v("p",[a._v("2.x core-site.xml\thdfs-site.xml\tyarn-site.xml\tmapred.site.xml\tslaves")]),a._v(" "),v("h2",{attrs:{id:"hdfs"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hdfs"}},[a._v("#")]),a._v(" HDFS")]),a._v(" "),v("p",[a._v("(Hadoop Distributed File System)，分布式文件系统")]),a._v(" "),v("p",[a._v("随着数据量越来越大，一个操作系统存不下所有数据，可以分配到多个操作系统上，HDFS就是来管理存储在多台机器上文件的系统。")]),a._v(" "),v("p",[a._v("优点：")]),a._v(" "),v("ul",[v("li",[a._v("高容错性，数据保存多个副本，某个副本丢失可以自动恢复")]),a._v(" "),v("li",[a._v("适合处理大数据，能处理数据规模PB级别的数据和处理百万规模以上的文件数量")]),a._v(" "),v("li",[a._v("可构建在廉价机器上")])]),a._v(" "),v("p",[a._v("缺点")]),a._v(" "),v("ul",[v("li",[a._v("不适合低延时数据访问")]),a._v(" "),v("li",[a._v("无法高效的对大量小文件进行存储")]),a._v(" "),v("li",[a._v("不支持并发写入、文件随机修改")])]),a._v(" "),v("h3",{attrs:{id:"架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#架构"}},[a._v("#")]),a._v(" 架构")]),a._v(" "),v("img",{staticStyle:{zoom:"80%"},attrs:{src:"C:\\Users\\zsh\\AppData\\Roaming\\Typora\\typora-user-images\\image-20210317162117849.png",alt:"image-20210317162117849"}}),a._v(" "),v("p",[a._v("NameNode：管理者")]),a._v(" "),v("ul",[v("li",[a._v("管理HDFS的名称空间")]),a._v(" "),v("li",[a._v("配置副本策略")]),a._v(" "),v("li",[a._v("管理数据块（Block）映射信息")]),a._v(" "),v("li",[a._v("处理客户端读写请求")])]),a._v(" "),v("p",[a._v("DataNode")]),a._v(" "),v("ul",[v("li",[a._v("存储实际的数据块")]),a._v(" "),v("li",[a._v("执行数据块的读/写操作")])]),a._v(" "),v("p",[a._v("Client")]),a._v(" "),v("ul",[v("li",[a._v("文件切分，文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传")]),a._v(" "),v("li",[a._v("与NameNode交互，获取文件的位置信息")]),a._v(" "),v("li",[a._v("与DataNode交互，读取或写入数据")]),a._v(" "),v("li",[a._v("Client提供一些命令来管理HDFS，比如NameNode格式化")]),a._v(" "),v("li",[a._v("Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作")])]),a._v(" "),v("p",[a._v("Secondary NameNode")]),a._v(" "),v("ul",[v("li",[a._v("辅助NameNode，分担其工作量，如定期合并Fsimage和Edits，并推送给NameNode")]),a._v(" "),v("li",[a._v("在紧急情况下可辅助恢复NameNode")])]),a._v(" "),v("p",[a._v("HDFS文件块大小")]),a._v(" "),v("p",[a._v("HDFS中的文件在物理上是分块存储，块的大小可以配置，在Hadoop2.x和3.x版本中是128M，1.X是64M。")]),a._v(" "),v("p",[a._v("为什么HDFS块大小默认是128M？")]),a._v(" "),v("p",[a._v("为什么不能远少于64MB(或128MB或256MB) （普通文件系统的数据块大小一般为4KB）减少硬盘寻道时间(disk seek time)")]),a._v(" "),v("p",[a._v("1.减少硬盘寻道时间")]),a._v(" "),v("p",[a._v("HDFS设计前提是支持大容量的流式数据操作，所以即使是一般的数据读写操作，涉及到的数据量都是比较大的。假如数据块设置过少，那需要读取的数据块就比较多，")]),a._v(" "),v("p",[a._v("由于数据块在硬盘上非连续存储，普通硬盘因为需要移动磁头，所以随机寻址较慢，读越多的数据块就增大了总的硬盘寻道时间。当硬盘寻道时间比io时间还要长的多时，那么硬盘寻道时间就成了系统的一个瓶颈。合适的块大小有助于减少硬盘寻道时间，提高系统吞吐量。")]),a._v(" "),v("p",[a._v("2.减少Namenode内存消耗")]),a._v(" "),v("p",[a._v("对于HDFS，他只有一个Namenode节点，他的内存相对于Datanode来说，是极其有限的。然而，namenode需要在其内存FSImage文件中中记录在Datanode中的数据块信息，假如数据块大小设置过少，而需要维护的数据块信息就会过多，那Namenode的内存可能就会伤不起了。")]),a._v(" "),v("p",[a._v("为什么不能远少于64MB(或128MB或256MB) （普通文件系统的数据块大小一般为4KB）减少硬盘寻道时间(disk seek time)")]),a._v(" "),v("p",[a._v("1.减少硬盘寻道时间")]),a._v(" "),v("p",[a._v("HDFS设计前提是支持大容量的流式数据操作，所以即使是一般的数据读写操作，涉及到的数据量都是比较大的。假如数据块设置过少，那需要读取的数据块就比较多，")]),a._v(" "),v("p",[a._v("由于数据块在硬盘上非连续存储，普通硬盘因为需要移动磁头，所以随机寻址较慢，读越多的数据块就增大了总的硬盘寻道时间。当硬盘寻道时间比io时间还要长的多时，那么硬盘寻道时间就成了系统的一个瓶颈。合适的块大小有助于减少硬盘寻道时间，提高系统吞吐量。")]),a._v(" "),v("p",[a._v("2.减少Namenode内存消耗")]),a._v(" "),v("p",[a._v("对于HDFS，他只有一个Namenode节点，他的内存相对于Datanode来说，是极其有限的。然而，namenode需要在其内存FSImage文件中中记录在Datanode中的数据块信息，假如数据块大小设置过少，而需要维护的数据块信息就会过多，那Namenode的内存可能就会伤不起了。")]),a._v(" "),v("p",[a._v("但是该参数也不会设置得过大。MapReduce中的map任务通常一次处理一个块中的数据，如果任务数太少（少于集群中的节点数量），作业的运行速度就会比较慢")]),a._v(" "),v("h3",{attrs:{id:"hdfs-2"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-2"}},[a._v("#")]),a._v(" HDFS")]),a._v(" "),v("h4",{attrs:{id:"写流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#写流程"}},[a._v("#")]),a._v(" 写流程")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210317192331715.png",alt:"image-20210317192331715"}})]),a._v(" "),v("p",[a._v("（1）客户端通过Distributed FileSystem 模块向NameNode 请求上传文件，NameNode 检查目标文件是否存在，父目录是否存在")]),a._v(" "),v("p",[a._v("（2）NameNode 返回是否可以上传。")]),a._v(" "),v("p",[a._v("（3）客户端请求第一个 Block 上传到哪几个DataNode 服务器上。")]),a._v(" "),v("p",[a._v("（4）NameNode 返回3 个DataNode 节点，分别为dn1、dn2、dn3。")]),a._v(" "),v("p",[a._v("（5）客户端通过FS DataOutputStream 模块请求dn1 上传数据，dn1 收到请求会继续调用dn2，然后dn2 调用dn3，将这个通信管道建立完成。")]),a._v(" "),v("p",[a._v("（6）dn1、dn2、dn3 逐级应答客户端。")]),a._v(" "),v("p",[a._v("（7）客户端开始往dn1 上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet 为单位，dn1 收到一个Packet 就会传给dn2，dn2 传给dn3；dn1 每传一个packet会放入一个应答队列等待应答。")]),a._v(" "),v("p",[a._v("（8）当一个Block 传输完成之后，客户端再次请求NameNode 上传第二个Block 的服务器。（重复执行3-7 步）。")]),a._v(" "),v("p",[a._v("副本结点选择")]),a._v(" "),v("p",[a._v("HDFS‘s palcement policy is to put one replica on the local machine if the writer is on a datanode, otherwise on a random datanode, another replica on a node in a different (remote) rack, and the last on a different node in the same remote rack.")]),a._v(" "),v("p",[a._v("源码副本结点选择：类BlockPlacementPolicyDefault中的chooseTargetInOrder方法")]),a._v(" "),v("h4",{attrs:{id:"读流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#读流程"}},[a._v("#")]),a._v(" 读流程")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210317195226647.png",alt:"image-20210317195226647"}})]),a._v(" "),v("p",[a._v("（1）客户端通过DistributedFileSystem 向NameNode 请求下载文件，NameNode 通过查询元数据，找到文件块所在的DataNode 地址。")]),a._v(" "),v("p",[a._v("（2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。")]),a._v(" "),v("p",[a._v("（3）DataNode 开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet 为单位来做校验）。")]),a._v(" "),v("p",[a._v("（4）客户端以Packet 为单位接收，先在本地缓存，然后写入目标文件。")]),a._v(" "),v("h3",{attrs:{id:"namenode和secondarynamenode"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#namenode和secondarynamenode"}},[a._v("#")]),a._v(" NameNode和SecondaryNameNode")]),a._v(" "),v("p",[a._v("NN和2NN的工作机制，保证数据的可靠性，能在故障中恢复过来")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210317210156227.png",alt:"image-20210317210156227"}})]),a._v(" "),v("p",[a._v("fsimage文件：HDFS文件系统元数据的一个永久性检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息")]),a._v(" "),v("p",[a._v("edits文件：存放HDFS文件系统的所有更新操作路径，文件系统客户端执行的所有写操作首先会被记录到edits文件中")]),a._v(" "),v("p",[a._v("每次NameNode启动的时候都会将Fsimage文件读入内存，加载Edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成NameNode启动的时候就将Fsimage和Edits文件进行了合并")]),a._v(" "),v("h3",{attrs:{id:"datanode"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#datanode"}},[a._v("#")]),a._v(" DataNode")]),a._v(" "),v("p",[a._v("作用")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210317210852682.png",alt:"image-20210317210852682"}})]),a._v(" "),v("h2",{attrs:{id:"mapreduce"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce"}},[a._v("#")]),a._v(" MapReduce")]),a._v(" "),v("p",[a._v("优点")]),a._v(" "),v("ul",[v("li",[a._v("易于编程，简单实现提供的接口，就可以完成一个分布式程序")]),a._v(" "),v("li",[a._v("良好的扩展性，可以简单增加机器扩展他的计算能力")]),a._v(" "),v("li",[a._v("高容错性，其中一台机器挂了，可以将任务转移到另一个节点上运行")])]),a._v(" "),v("p",[a._v("缺点")]),a._v(" "),v("ul",[v("li",[a._v("不擅长实时计算，计算的中间结果要写磁盘")]),a._v(" "),v("li",[a._v("不擅长流式计算，mr输入数据是静态的")]),a._v(" "),v("li",[a._v("不擅长DAG（有向无环图）计算，DAG计算是指多个应用程序的输入存在依赖关系，后一个应用程序的输入是前一个的输出")])]),a._v(" "),v("p",[a._v("框架原理")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210319190717516.png",alt:"image-20210319190717516"}})]),a._v(" "),v("p",[a._v("InputFormat")]),a._v(" "),v("img",{staticStyle:{zoom:"80%"},attrs:{src:"C:\\Users\\zsh\\AppData\\Roaming\\Typora\\typora-user-images\\image-20210319190955521.png",alt:"image-20210319190955521"}}),a._v(" "),v("p",[a._v("切片与MapTask并行度决定机制")]),a._v(" "),v("p",[a._v("FileInputFormat切片源码解析")]),a._v(" "),v("ul",[v("li",[a._v("遍历目录下的每一个文件（对每个文件单独切分）")]),a._v(" "),v("li",[a._v("默认情况下切分大小为BlockSize=128M")]),a._v(" "),v("li",[a._v("每次切片时，都要判断切完剩下的部分是否大于块的1.1倍（remain / blocksize <= 1.1），不大于1.1倍就划分为一块")]),a._v(" "),v("li",[a._v("只记录切片的元数据信息，比如起始位置、长度以及所在的结点列表")]),a._v(" "),v("li",[a._v("提交切片规划文件到yarn，yarn上的mr AppMaster就可以根据切片规划文件计算开启MapTask个数")])]),a._v(" "),v("p",[a._v("CombineTextInputFormat切片机制")]),a._v(" "),v("p",[a._v("上述切片对每个文件进行单独切分，如果有大量小文件，会产生大量MapTask，处理效率低下，CombineTextInputFormat可以用于小文件过多的场景，可以将多个小文件从逻辑上规划到一个切片中。")]),a._v(" "),v("p",[a._v("MapReduce工作流程")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210720203255256.png",alt:"image-20210720203255256"}})]),a._v(" "),v("p",[a._v("以WordCount为例讲解执行流程")]),a._v(" "),v("ul",[v("li",[a._v("Read阶段：将文件读入内存，默认以换行符作文分隔将每一行丢到用户编写Map函数")]),a._v(" "),v("li",[a._v("Map阶段：解析每一行为key/value形式，这里就是将一行的单词提取出来，分解成<word, 1>的形式")]),a._v(" "),v("li",[a._v("Collect阶段：将map生成的键值对写入到环形缓存区")]),a._v(" "),v("li",[a._v("Spill（溢写）阶段：当环形缓存区之后，使用快速排序对数据进行排序，然后写到文件中")]),a._v(" "),v("li",[a._v("Merge阶段：最后使用归并排序将多个文件合并成一个文件")])]),a._v(" "),v("p",[a._v("详细流程")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210319193552571.png",alt:"image-20210319193552571"}})]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210319193606776.png",alt:"image-20210319193606776"}})]),a._v(" "),v("p",[a._v("Shuffle机制")]),a._v(" "),v("p",[a._v("在Map方法之后，在Reduce方法之前的数据处理过程叫做Shuffle")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210319193708928.png",alt:"image-20210319193708928"}})]),a._v(" "),v("p",[a._v("Partition分区")]),a._v(" "),v("p",[a._v("自定义分区可以继承Partitioner类，重写getPartition()方法")]),a._v(" "),v("ul",[v("li",[a._v("ReduceTask为1，则只会产生一个文件")]),a._v(" "),v("li",[a._v("分区数 > ReduceTask，报错")]),a._v(" "),v("li",[a._v("分区数 < ReduceTask，产生多个空文件")])]),a._v(" "),v("p",[a._v("WritableComparable")]),a._v(" "),v("p",[a._v("MapTask在溢写到磁盘时会对数据进行快速排序，如果溢写了多个文件则对这些文件进行归并排序")]),a._v(" "),v("p",[a._v("ReduceTask在拉取多个MapTask产生的数据时会进行归并排序，都是按照数据"),v("strong",[a._v("key")]),a._v("排序")]),a._v(" "),v("p",[a._v("自定义排序可以实现WritableComparable接口，重写里边的compareTo方法即可。")]),a._v(" "),v("p",[a._v("Combiner合并")]),a._v(" "),v("ul",[v("li",[a._v("Combiner组件的父类就是Reducer")]),a._v(" "),v("li",[a._v("Combiner和Reducer的区别在于运行的位置，Combiner时在每一个MapTask溢写快速排序后运行，也在归并排序多个溢写文件后运行")]),a._v(" "),v("li",[a._v("Combiner能够对每一个MapTask的输出进行局部汇总，以减少网络传输量")]),a._v(" "),v("li",[a._v("Combiner能够应用的前题是不能影响最终的业务逻辑，wordcount可以，但是求平均值不行")])]),a._v(" "),v("p",[a._v("OutputFormat")]),a._v(" "),v("img",{staticStyle:{zoom:"80%"},attrs:{src:"C:\\Users\\zsh\\AppData\\Roaming\\Typora\\typora-user-images\\image-20210319195323653.png",alt:"image-20210319195323653"}}),a._v(" "),v("p",[a._v("定义输出数据的格式，默认输出格式是TextOutputFormat")]),a._v(" "),v("p",[a._v("ReduceTask并行度决定机制")]),a._v(" "),v("p",[a._v("MapTask并行度由切片个数决定，切片个数由输入文件和切片规则决定。")]),a._v(" "),v("ul",[v("li",[a._v("ReduceTask=0，没有Reduce阶段")]),a._v(" "),v("li",[a._v("ReduceTask=1，不执行分区过程")]),a._v(" "),v("li",[a._v("ReduceTask数据并不是任意设置，还要考虑业务逻辑需求和集群性能，有些情况下需要计算全局汇总结果，就只能有1个ReduceTask")])]),a._v(" "),v("p",[a._v("数据倾斜及其解决方案")]),a._v(" "),v("p",[a._v("Hadoop数据压缩")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210319202005163.png",alt:"image-20210319202005163"}})]),a._v(" "),v("h2",{attrs:{id:"yarn"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#yarn"}},[a._v("#")]),a._v(" Yarn")]),a._v(" "),v("h3",{attrs:{id:"yarn基础架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#yarn基础架构"}},[a._v("#")]),a._v(" Yarn基础架构")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210320165938094.png",alt:"image-20210320165938094"}})]),a._v(" "),v("h3",{attrs:{id:"yarn工作机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#yarn工作机制"}},[a._v("#")]),a._v(" Yarn工作机制")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210320170005311.png",alt:"image-20210320170005311"}})]),a._v(" "),v("p",[a._v("HDFS、Yarn、MapReduce三者关系")]),a._v(" "),v("p",[v("img",{attrs:{src:"C:%5CUsers%5Czsh%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210320170431261.png",alt:"image-20210320170431261"}})]),a._v(" "),v("p",[a._v("Yarn作业提交过程")]),a._v(" "),v("p",[a._v("Yarn调度器和调度算法")]),a._v(" "),v("ul",[v("li",[a._v("FIFO调度器")]),a._v(" "),v("li",[a._v("容量调度器（Capacity Scheduler）")]),a._v(" "),v("li",[a._v("公平调度器（Fair Schedule）")])]),a._v(" "),v("p",[a._v("FIFO调度器")]),a._v(" "),v("p",[a._v("单队列，根据提交作业的先后顺序，先来先服务")]),a._v(" "),v("p",[a._v("容量调度器")]),a._v(" "),v("p",[a._v("公平调度器")]),a._v(" "),v("h2",{attrs:{id:"组件间的通信机制-rpc"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#组件间的通信机制-rpc"}},[a._v("#")]),a._v(" 组件间的通信机制-RPC")])])}),[],!1,null,null,null);e.default=t.exports}}]);