(window.webpackJsonp=window.webpackJsonp||[]).push([[113],{597:function(v,_,t){"use strict";t.r(_);var l=t(4),a=Object(l.a)({},(function(){var v=this,_=v.$createElement,t=v._self._c||_;return t("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[t("p",[v._v("star法则")]),v._v(" "),t("ul",[t("li",[v._v("situation(在什么样的情况发生的，具体需求是什么)")]),v._v(" "),t("li",[v._v("task(具体的任务)")]),v._v(" "),t("li",[v._v("action(针对这样的情况和任务，我是怎么采取行动的)")]),v._v(" "),t("li",[v._v("result(结果如何，所做的事产生的影响，收获是什么)")])]),v._v(" "),t("h4",{attrs:{id:"新工单系统"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#新工单系统"}},[v._v("#")]),v._v(" 新工单系统")]),v._v(" "),t("p",[v._v("situation")]),v._v(" "),t("ul",[t("li",[v._v("老工单bug不断，运维费时")]),v._v(" "),t("li",[v._v("老工单的架构前后端不分离，没有使用任何流程引擎和开源组件，代码不易扩展和维护")])]),v._v(" "),t("p",[v._v("task")]),v._v(" "),t("ul",[t("li",[v._v("技术选型\n"),t("ul",[t("li",[v._v("自研，之前的就是自研的，如果再自研一套代码量大，工作量大")]),v._v(" "),t("li",[v._v("Activity，支持BPMN标准的流程定义语言，提供完善的流程控制支持")]),v._v(" "),t("li",[v._v("Flowable，是之前Activity团队离开之前公司在Activity6.0分支的基础上开发的，有更加完善的功能，如支持表单，支持REST API进行HTTP调用，国内盘古BPM做的比较完善的流程引擎系统也是基于Flowable")])])]),v._v(" "),t("li",[v._v("整理老工单的功能，需要全部在新工单上实现")])]),v._v(" "),t("p",[v._v("action")]),v._v(" "),t("ul",[t("li",[v._v("前后端分离，使用流程引擎Flowable开发，开发一套简单工单适配老工单系统，开发复杂工单作为扩展支持复杂的流程定义")]),v._v(" "),t("li",[v._v("新工单的适配工作，不能一股脑直接全部迁移到新工单，需要做适配工作\n"),t("ul",[t("li",[v._v("如爱奇艺云展示工单列表页面分别展示新工单和老工单，涉及到两个不同数据源分页的问题")]),v._v(" "),t("li",[v._v("新工单同步OA审批中心，在老工单中，工单都是要同步给OA的，然后OA那边也可以进行工单审批，驳回，评论一些列操作嘛。新工单同步OA是这样做的，我们可以将根据OA提供的接口把工单信息同步、审批操作同步过去，然后那边操作新工单的话还是调的老工单的接口嘛，我们在老工单系统里做了消息的转发，转发到新工单完成信息的同步的。")])])])]),v._v(" "),t("p",[v._v("result")]),v._v(" "),t("ul",[t("li",[v._v("完成新工单系统，能够适配老工单系统的功能，且扩展了复杂工单流程")]),v._v(" "),t("li",[v._v("收获了项目经验，学会使用设计模式增加项目的可维护性和扩展性")])]),v._v(" "),t("h4",{attrs:{id:"螺丝配卡"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#螺丝配卡"}},[v._v("#")]),v._v(" 螺丝配卡")]),v._v(" "),t("p",[t("strong",[v._v("situation")])]),v._v(" "),t("p",[v._v("我们在使用图像围栏的时候，需要给不同的服务配GPU卡，比如我给人脸特征抽取配8张卡，我们可以有1个实例配8卡，4实例每个配两卡策略，这4个实例分配到不同的机器上，不同分配策略不一样，它们有不同的QPS、内存和CPU消耗，这其实跟服务有关系，有些服务偏向于IO密集型，有些偏向计算密集型，计算密集型的服务均分到不同的机器上能够充分利用CPU资源，而IO密集型的服务应该尽量起1个实例，分在一台机器上会好些。")]),v._v(" "),t("p",[t("strong",[v._v("task")])]),v._v(" "),t("p",[v._v("所以，我的任务就是我们在给各个服务配好GPU卡之后，考量整体的服务给出一个每一个服务的实例数与它的GPU卡数。")]),v._v(" "),t("p",[t("strong",[v._v("action")])]),v._v(" "),t("ul",[t("li",[v._v("当然，首先第一步就是判断每一个服务是计算密集型还是IO密集型的，这需要通过业务逻辑和性能测试两个方面来做判断")]),v._v(" "),t("li",[v._v("我们将所有的服务归好类，我们要综合所有服务使用特定的算法得到每一个服务的分配策略")])]),v._v(" "),t("p",[t("strong",[v._v("result")])]),v._v(" "),t("p",[v._v("测试")]),v._v(" "),t("p",[v._v("对照实验")]),v._v(" "),t("ul",[t("li",[v._v("所有服务统统分配1*n，1卡多实例")]),v._v(" "),t("li",[v._v("所有服务统统1实例，多卡1实例")]),v._v(" "),t("li",[v._v("我的分配方法")])]),v._v(" "),t("p",[v._v("对比1卡多实例，有着更高的qps且有更低的cpu内存消耗")]),v._v(" "),t("p",[v._v("对比多卡1实例，内存cpu消耗稍微高一些，但是qps更高")]),v._v(" "),t("p",[t("strong",[v._v("action details")])]),v._v(" "),t("p",[v._v("其实就是在集群资源有限的情况下，要尽可能让计算密集型的服务分配到多台机子上，而IO密集的尽量在更少的机器上")]),v._v(" "),t("p",[v._v("其实这个问题有点像背包问题，我们有多个机器，每台机器有GPU资源，就好像有多个背包，背包就是机器，容量就是GPU资源，对于不同的服务，不同的装法能够产生不同的价值，然后怎么装能够使得价值最大化。")]),v._v(" "),t("p",[v._v("但是我最后的解决方案其实并没有用背包的方法来解决，而是使用暴力枚举的方式做的，主要有两点考虑")]),v._v(" "),t("ul",[t("li",[v._v("一是考虑到我们集群的资源是有限的，一个集群上的机器就十几台，使用动态规划的话主要是它有一些最优子结构，可以优化时间复杂度，但我们数据量是很小的，没有必要")]),v._v(" "),t("li",[v._v("二是为代码的可维护性、易读性考虑，写一个简单易懂的代码对自己或者后来者都是一种解脱吧")])]),v._v(" "),t("p",[v._v("我想的方法就是对于一个服务，枚举它所有可能的划分方法，比如当前服务配了8卡，当前集群有4台机器，那么我们就可以4个实例两张卡，2个实例张卡，1个实例八张卡，对于所有服务我们都这么做，然后我们将每一个服务都抽出一个划分方案出来，组合起来就得到一种所有服务的调度方案，我们可以将这些服务的划分方案一一组合，就能够得到所有的调度方案，对于每一个调度方案，怎么去区分它们是好是坏呢?")]),v._v(" "),t("p",[v._v("我们主要是基于一个点：让IO密集型服务尽可能在少的机器上运行，计算密集的服务尽可能平分到多台机器上，以充分利用CPU资源")]),v._v(" "),t("p",[v._v("所以我对每一个调度方案进行打分，")]),v._v(" "),t("ul",[t("li",[v._v("对于IO密集型的服务，它的分数是p/k，p是卡数，k是实例数，就说k越小它的分数就越大，")]),v._v(" "),t("li",[v._v("对于计算密集型的服务，它的分数是p*k/n，p是卡数，k是实例数，n是机器数，就是说k越大，它的分数越大。")])]),v._v(" "),t("p",[v._v("给所有的调度方案打分之后，按照从大到小排序，分数越高其实就越符合我们的刚才基于的点")]),v._v(" "),t("p",[v._v("但其实并不是每一个调度方案都能够被大螺丝调度的，有些调度方案是不合理的，就比如说我们有2台4卡的机器，如果2个服务配4卡，一个服务的调度方案为1机器4卡，另一个服务2机器2卡，那么这样的调度方案是不合理的。")]),v._v(" "),t("p",[v._v("所以我需要使用一种方法去验证一种调度方案是否合理，我使用一种贪心的策略，去每次先放需求GPU卡多的到当前还剩GPU最多的机器上，如果有GPU卡分配不到任何一台机器上，那么就换下一个策略，如果能够分配完，就选择该种调度策略")]),v._v(" "),t("p",[v._v("针对配卡问题我也做了测试，一方面是功能测试，另一个是性能测试，功能测试主要测试配卡策略能不能够正常工作，能不能正确调度到集群，性能测试主要考虑两个点")]),v._v(" "),t("ul",[t("li",[v._v("一个是如何测试能够得到较为准确的负载，该负载应该与服务所能承载的真实负载接近")]),v._v(" "),t("li",[v._v("第二个是面对很多不同的服务，如何设计一套通用的测试框架以尽可能提高代码的可复用性、维护性、扩展性")])]),v._v(" "),t("p",[v._v("实现，编写一个测试基类，有")]),v._v(" "),t("ul",[t("li",[v._v("线程安全的计数器")]),v._v(" "),t("li",[v._v("产生恒定QPS的压力控制器，内部使用一个线程安全的队列，往队列中按照恒定的QPS打数据，主任务从队列中取到数据才能发送请求，没有取到数据则等待")]),v._v(" "),t("li",[v._v("活性检查和qps统计")]),v._v(" "),t("li",[v._v("主任务，不同的服务有不同的逻辑")])]),v._v(" "),t("p",[v._v("如果在某个qps内，在一段时间内，检测错误率不大于1%，且压力控制队列数据恒定，就说该服务能够承担这个QPS的压力")]),v._v(" "),t("h4",{attrs:{id:"lrucache"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#lrucache"}},[v._v("#")]),v._v(" LruCache")]),v._v(" "),t("p",[v._v("situation")]),v._v(" "),t("p",[v._v("网站上经常展示一些摄像头抓拍的图片、用户人像库的图片，而这些图片存储在数据库中，每次获取图片需要从远端数据库中拿，这样延迟较高，限制了网站的qps")]),v._v(" "),t("p",[v._v("task")]),v._v(" "),t("p",[v._v("所以我的就一方面想对图片加缓存，另一方面这个缓存占用的内存还需要控制在一个相对固定的区间，")]),v._v(" "),t("p",[v._v("action")]),v._v(" "),t("p",[v._v("so引入了一种带有清退机制的缓存结构LruCache(Least Recently Used Cache)，在目前的系统中，使用LruCache + 键值存储数据库的机制将远端数据变为本地缓存数据，不仅能够降低平均获取信息的耗时，而且通过一定的清退机制，也可以维持服务内存占用在安全区间。")]),v._v(" "),t("p",[v._v("result")]),v._v(" "),t("p",[v._v("后端获取图片的延时降低了")]),v._v(" "),t("p",[t("strong",[v._v("改进：Hash分片")])]),v._v(" "),t("p",[v._v("LruCache引入后，在一段时间内较好地支持了业务的发展。随着业务的迭代，单机QPS持续上升。在更高QPS下，LruCache的查询耗时有了明显的提高，逐渐无法适应低平响的业务场景。在这种情况下，引入了HashLruCache机制以解决这个问题。")]),v._v(" "),t("p",[v._v("LruCache在高QPS下的耗时增加原因分析：")]),v._v(" "),t("p",[v._v("线程安全的LruCache中有锁的存在。每次读写操作之前都有加锁操作，完成读写操作之后还有解锁操作。在低QPS下，锁竞争的耗时基本可以忽略；但是在高QPS下，大量的时间消耗在了等待锁的操作上，导致耗时增长。")]),v._v(" "),t("p",[v._v("HashLruCache适应高QPS场景：")]),v._v(" "),t("p",[v._v("针对大量的同步等待操作导致耗时增加的情况，解决方案就是尽量减小临界区。引入Hash机制，对全量数据做分片处理，在原有LruCache的基础上形成HashLruCache，以降低查询耗时。")]),v._v(" "),t("p",[v._v("HashLruCache引入某种哈希算法，将缓存数据分散到N个LruCache上。最简单的哈希算法即使用取模算法，将图片信息按照其ID取模，分散到N个LruCache上。查询时也按照相同的哈希算法，先获取数据可能存在的分片，然后再去对应的分片上查询数据。这样可以增加LruCache的读写操作的并行度，减小同步等待的耗时。")])])}),[],!1,null,null,null);_.default=a.exports}}]);